{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d146e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "class LinkedinScraper:\n",
    "    \n",
    "    # Define the two lists to concatenate\n",
    "    DataScience = ['Data Science', 'Big data', 'Machine learning','ML', 'Data mining', 'Artificial intelligence', 'AI', 'Predictive modeling',\n",
    "               'Statistical analysis', 'Data visualization', 'Deep learning', 'Natural language processing', 'Business intelligence',\n",
    "               'Data warehousing', 'Data management', 'Data cleaning', 'Feature engineering', 'Time series analysis', 'Text analytics',\n",
    "               'Database', 'SQL', 'NoSQL', 'Neural networks', 'Regression analysis', 'Clustering', 'Dimensionality reduction',\n",
    "               'Anomaly detection', 'Recommender systems', 'Data integration', 'Data governance']\n",
    "    \n",
    "    MachineLearning = ['Machine learning', 'Data preprocessing', 'Feature selection', 'Feature engineering', 'Data visualization',\n",
    "                   'Model selection', 'Hyperparameter tuning', 'Cross-validation', 'Ensemble methods', 'Neural networks', 'Deep learning',\n",
    "                   'Convolutional neural networks', 'Recurrent neural networks', 'Natural language processing', 'Computer vision',\n",
    "                   'Reinforcement learning', 'Unsupervised learning', 'Clustering', 'Dimensionality reduction', 'Bayesian methods',\n",
    "                   'Time series analysis', 'Random forest', 'Gradient boosting', 'Support vector machines', 'Decision trees', 'Regression analysis']\n",
    "\n",
    "    # Concatenate the two lists\n",
    "    keywords = DataScience + MachineLearning\n",
    "    \n",
    "    def __init__(self, country_name, geoId, companies):\n",
    "        self.country_name = country_name\n",
    "        self.geoId = geoId\n",
    "        self.companies = companies\n",
    "        self.search_url_pattern = 'https://www.linkedin.com/jobs/search/?currentJobId={}&distance=25&geoId={}&keywords={}&refresh=true&start={}'\n",
    "\n",
    "    \n",
    "    \n",
    "    def scrape_jobs(self, output_file_path):\n",
    "        start_index = 0\n",
    "        jobs_per_page = 25\n",
    "        total_jobs_downloaded = 0        \n",
    "        \n",
    "        \n",
    "        # Iterate over each company and search for matching jobs\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            for i, company in enumerate(self.companies):\n",
    "                print(f\"Company {i+1}: {company}\")\n",
    "                jobs_downloaded = 0\n",
    "                # Iterate until no matching jobs are found\n",
    "                while True:\n",
    "                    # Construct the search URL\n",
    "                    search_url = self.search_url_pattern.format(start_index, self.geoId, company, start_index)\n",
    "\n",
    "                    # Send a GET request to the search URL\n",
    "                    response = requests.get(search_url)\n",
    "\n",
    "                    # Parse the HTML content of the page using BeautifulSoup\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                    # Find all the job posting URLs on the page\n",
    "                    job_urls = [a['href'] for a in soup.find_all('a', href=True) if '/jobs/view/' in a['href']]\n",
    "\n",
    "                    # If no matching jobs are found, break the loop\n",
    "                    if len(job_urls) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Iterate over each job URL and extract the job information\n",
    "                    for job_url in job_urls:               \n",
    "\n",
    "                        # Send a GET request to the job URL\n",
    "\n",
    "                        response = requests.get(job_url)\n",
    "\n",
    "                        # Parse the HTML content of the page using BeautifulSoup\n",
    "                        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                        # Find the job title and company name\n",
    "                        title = soup.find('h1', class_='topcard__title')\n",
    "                        if title is not None:\n",
    "                            title = title.text.strip()\n",
    "                        else:\n",
    "                            continue\n",
    "                        company_name = soup.find('a', class_='topcard__org-name-link')\n",
    "                        if company_name is not None:\n",
    "                            company_name = company_name.text.strip()\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        # Find the div tag that contains the job description\n",
    "                        description_div = soup.find('div', class_='description__text')\n",
    "\n",
    "                        if description_div is not None:\n",
    "                            # Extract the job description text\n",
    "                            job_description = description_div.get_text().strip()\n",
    "                            job_description = job_description.replace('Show more', '').replace('Show less', '')\n",
    "\n",
    "                            # Remove any extra spaces from the job description\n",
    "                            job_description = ' '.join(job_description.split())\n",
    "\n",
    "\n",
    "                            found_keywords = [keyword for keyword in self.keywords if keyword in job_description]                      \n",
    "\n",
    "                            if found_keywords:\n",
    "                                job_info = {\n",
    "                                    'Country_name': self.country_name,\n",
    "                                    'company_name': company_name,\n",
    "                                    'keywords': found_keywords,\n",
    "                                    'description': job_description \n",
    "                                } \n",
    "                                \n",
    "                                with open(output_file_path, 'a', encoding='utf-8') as json_file:\n",
    "                                    json.dump(job_info, json_file, ensure_ascii=False)\n",
    "                                    json_file.write('\\n')\n",
    "                                \n",
    "                                jobs_downloaded += 1\n",
    "                                total_jobs_downloaded += 1                       \n",
    "                        \n",
    "                    \n",
    "                                print(f\"         Job {jobs_downloaded}: {title} downloaded!\") \n",
    "                            \n",
    "                \n",
    "                if jobs_downloaded == 0:\n",
    "                    print(f\"         No jobs found for {company}\")  \n",
    "                            \n",
    "                        \n",
    "        print()\n",
    "        print(\"Total {} jobs downloaded!\".format(total_jobs_downloaded ))                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89b773",
   "metadata": {},
   "source": [
    "## Scrappigng data for Denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  Denmark\n",
      "\n",
      "Company 1: Maersk\n",
      "         Job 1: Maersk Supply Service A/S - Procurement Project Manager - Renewables downloaded!\n",
      "         Job 2: Lead Infrastructure Architect downloaded!\n",
      "         Job 3: Analytics Engineer downloaded!\n",
      "         Job 4: Lead Infrastructure Architect downloaded!\n",
      "         Job 5: Analytics Engineer downloaded!\n",
      "         Job 6: Analytics Engineer downloaded!\n",
      "Company 2: Danske Bank\n",
      "         Job 1: Skilled Business/Data Analyst in Impairment Data Analytics downloaded!\n",
      "         Job 2: Software Engineer downloaded!\n",
      "         Job 3: Skilled Business/Data Analyst in Impairment Data Analytics downloaded!\n",
      "         Job 4: Senior Analyst in Group Treasury, Liquidity Steering downloaded!\n",
      "Company 3: William Demant Holding\n",
      "         No jobs found for William Demant Holding\n",
      "Company 4: Nets\n",
      "         No jobs found for Nets\n",
      "Company 5: Ambu A/S\n",
      "         No jobs found for Ambu A/S\n",
      "Company 6: NNIT\n",
      "         Job 1: Application Manager downloaded!\n",
      "         Job 2: Senior Business Intelligence Developer to join our exciting data journey downloaded!\n",
      "         Job 3: Application Manager downloaded!\n",
      "Company 7: Bang & Olufsen\n",
      "         No jobs found for Bang & Olufsen\n",
      "Company 8: DFDS\n",
      "         No jobs found for DFDS\n",
      "Company 9: FLSmidth\n",
      "         No jobs found for FLSmidth\n",
      "Company 10: Workday\n",
      "         No jobs found for Workday\n",
      "Company 11: Boston Consulting Group (BCG)\n",
      "         No jobs found for Boston Consulting Group (BCG)\n",
      "Company 12: the LEGO Group\n",
      "         No jobs found for the LEGO Group\n",
      "Company 13: Antler\n"
     ]
    }
   ],
   "source": [
    "country_name= \"Denmark\"\n",
    "geoId=\"104514075\"\n",
    "companies=['Maersk', 'Danske Bank', 'William Demant Holding', 'Nets', 'Ambu A/S', 'NNIT', 'Bang & Olufsen', 'DFDS', 'FLSmidth', 'Workday', 'Boston Consulting Group (BCG)', 'the LEGO Group', 'Antler', 'DTU - Technical University of Denmark', 'ATLANT 3D', 'Silo AI', 'ROCKWOOL Group', 'Corti', 'Accenture Nordics', 'TELUS International AI Data Solutions', 'Appen', 'IT-Universitetet i København', 'Nigel Frank International', 'Capgemini', 'TELUS International', 'Mindway AI']\n",
    "\n",
    "\n",
    "print(\"Country: \", country_name)\n",
    "print()\n",
    "\n",
    "scraper = LinkedinScraper(country_name, geoId, companies )\n",
    "scraper.scrape_jobs(\"DS_jobs_denmark.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecba02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46a9df97",
   "metadata": {},
   "source": [
    "# full stalk Denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b855608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "class LinkedinScraper:    \n",
    "\n",
    "    # Concatenate the two lists\n",
    "    keywords = ['Front-end development', 'HTML', 'CSS', 'JavaScript', 'React', 'Angular', 'Vue.js', 'Bootstrap', 'jQuery', 'responsive design',      'Back-end development', 'Node.js', 'Python', 'Ruby', 'PHP', 'Java', '.NET', 'SQL', 'NoSQL', 'RESTful APIs', 'web servers',      'Database management', 'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Cassandra', 'Oracle', 'SQL Server',      'DevOps', 'AWS', 'Azure', 'Google Cloud', 'Docker', 'Kubernetes', 'Git', 'Jenkins', 'Travis CI', 'CircleCI', 'monitoring and logging tools',      'Project management', 'Agile', 'Scrum', 'Kanban', 'JIRA', 'Trello', 'Asana', 'project planning', 'team collaboration', 'communication skills']\n",
    "\n",
    "    \n",
    "    def __init__(self, country_name, geoId, companies):\n",
    "        self.country_name = country_name\n",
    "        self.geoId = geoId\n",
    "        self.companies = companies\n",
    "        self.search_url_pattern = 'https://www.linkedin.com/jobs/search/?currentJobId={}&distance=25&geoId={}&keywords={}&refresh=true&start={}'\n",
    "\n",
    "    \n",
    "    \n",
    "    def scrape_jobs(self, output_file_path):\n",
    "        start_index = 0\n",
    "        jobs_per_page = 25\n",
    "        total_jobs_downloaded = 0        \n",
    "        \n",
    "        \n",
    "        # Iterate over each company and search for matching jobs\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            for i, company in enumerate(self.companies):\n",
    "                print(f\"Company {i+1}: {company}\")\n",
    "                jobs_downloaded = 0\n",
    "                # Iterate until no matching jobs are found\n",
    "                while True:\n",
    "                    # Construct the search URL\n",
    "                    search_url = self.search_url_pattern.format(start_index, self.geoId, company, start_index)\n",
    "\n",
    "                    # Send a GET request to the search URL\n",
    "                    response = requests.get(search_url)\n",
    "\n",
    "                    # Parse the HTML content of the page using BeautifulSoup\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                    # Find all the job posting URLs on the page\n",
    "                    job_urls = [a['href'] for a in soup.find_all('a', href=True) if '/jobs/view/' in a['href']]\n",
    "\n",
    "                    # If no matching jobs are found, break the loop\n",
    "                    if len(job_urls) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Iterate over each job URL and extract the job information\n",
    "                    for job_url in job_urls:               \n",
    "\n",
    "                        # Send a GET request to the job URL\n",
    "\n",
    "                        response = requests.get(job_url)\n",
    "\n",
    "                        # Parse the HTML content of the page using BeautifulSoup\n",
    "                        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                        # Find the job title and company name\n",
    "                        title = soup.find('h1', class_='topcard__title')\n",
    "                        if title is not None:\n",
    "                            title = title.text.strip()\n",
    "                        else:\n",
    "                            continue\n",
    "                        company_name = soup.find('a', class_='topcard__org-name-link')\n",
    "                        if company_name is not None:\n",
    "                            company_name = company_name.text.strip()\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        # Find the div tag that contains the job description\n",
    "                        description_div = soup.find('div', class_='description__text')\n",
    "\n",
    "                        if description_div is not None:\n",
    "                            # Extract the job description text\n",
    "                            job_description = description_div.get_text().strip()\n",
    "                            job_description = job_description.replace('Show more', '').replace('Show less', '')\n",
    "\n",
    "                            # Remove any extra spaces from the job description\n",
    "                            job_description = ' '.join(job_description.split())\n",
    "\n",
    "\n",
    "                            found_keywords = [keyword for keyword in self.keywords if keyword in job_description]                      \n",
    "\n",
    "                            if found_keywords:\n",
    "                                job_info = {\n",
    "                                    'Country_name': self.country_name,\n",
    "                                    'company_name': company_name,\n",
    "                                    'keywords': found_keywords,\n",
    "                                    'description': job_description \n",
    "                                } \n",
    "                                \n",
    "                                with open(output_file_path, 'a', encoding='utf-8') as json_file:\n",
    "                                    json.dump(job_info, json_file, ensure_ascii=False)\n",
    "                                    json_file.write('\\n')\n",
    "                                \n",
    "                                jobs_downloaded += 1\n",
    "                                total_jobs_downloaded += 1                       \n",
    "                        \n",
    "                    \n",
    "                                print(f\"         Job {jobs_downloaded}: {title} downloaded!\") \n",
    "                            \n",
    "                \n",
    "                if jobs_downloaded == 0:\n",
    "                    print(f\"         No jobs found for {company}\")  \n",
    "                            \n",
    "                        \n",
    "        print()\n",
    "        print(\"Total {} jobs downloaded!\".format(total_jobs_downloaded ))                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33bc30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  Denmark\n",
      "\n",
      "Company 1: Trustpilot\n",
      "         Job 1: Engineering Manager - Business Systems downloaded!\n",
      "         Job 2: Software Engineering Lead - Marketing downloaded!\n",
      "         Job 3: Business Development Manager, FinTech downloaded!\n",
      "         Job 4: Engineering Manager - Business Systems downloaded!\n",
      "         Job 5: Engineering Manager - Business Systems downloaded!\n",
      "         Job 6: Software Engineering Lead - Marketing downloaded!\n",
      "         Job 7: Engineering Manager - Business Systems downloaded!\n",
      "         Job 8: Software Engineering Lead - Marketing downloaded!\n",
      "         Job 9: Business Development Manager, FinTech downloaded!\n",
      "Company 2: BESTSELLER\n",
      "         Job 1: User Experience Intern downloaded!\n",
      "         Job 2: Communication Student Worker downloaded!\n",
      "         Job 3: Backend Developer downloaded!\n",
      "         Job 4: Backend Developer - Brand Tech Department downloaded!\n",
      "         Job 5: Server Infrastructure Specialist downloaded!\n",
      "         Job 6: Student Worker for Network Service Automations downloaded!\n",
      "Company 3: Canonical\n",
      "         No jobs found for Canonical\n",
      "Company 4: HCLTech\n",
      "         Job 1: Data Engineer downloaded!\n",
      "         Job 2: Cloud Engineer downloaded!\n",
      "         Job 3: Javaudvikler downloaded!\n",
      "         Job 4: IIB udvikler downloaded!\n",
      "         Job 5: Data Engineer downloaded!\n",
      "Company 5: Randstad Danmark\n",
      "         Job 1: Cloud Developer hos Trelleborg downloaded!\n",
      "         Job 2: Mobile developer ios downloaded!\n",
      "Company 6: the LEGO Group\n",
      "         Job 1: Senior Executive Assistant to COO downloaded!\n",
      "         Job 2: Senior Finance Manager – Distribution & Planning downloaded!\n",
      "         Job 3: Manager, Analytics Strategist downloaded!\n",
      "         Job 4: Senior Executive Assistant to COO downloaded!\n",
      "         Job 5: Senior Executive Assistant to CMO downloaded!\n",
      "         Job 6: Senior Finance Manager downloaded!\n",
      "         Job 7: Technical Operations Specialist downloaded!\n",
      "         Job 8: Engineer – LEGO® Digital Design Platform downloaded!\n",
      "Company 7: Mover Systems\n",
      "         Job 1: Senior Copywriter downloaded!\n",
      "         Job 2: Cloud Infrastructure Engineer (DevOps) downloaded!\n",
      "         Job 3: Senior .NET Core Developer downloaded!\n",
      "Company 8: Netcompany\n",
      "         No jobs found for Netcompany\n",
      "Company 9: Schibsted\n",
      "         No jobs found for Schibsted\n",
      "Company 10: Danfoss\n",
      "         Job 1: Business Controller (m/f/d) downloaded!\n",
      "         Job 2: Business Controller (m/f/d) downloaded!\n",
      "         Job 3: Senior Project Manager, Applications & Systems downloaded!\n",
      "         Job 4: Business Controller (m/f/d) downloaded!\n",
      "         Job 5: Finance Business Partner downloaded!\n",
      "         Job 6: Strategy Manager (Nordborg, DK) downloaded!\n",
      "         Job 7: Senior Project Manager, Applications & Systems downloaded!\n",
      "         Job 8: Senior Project Manager, Applications & Systems downloaded!\n",
      "         Job 9: Sales Digital Business Director downloaded!\n",
      "         Job 10: Customer Service Director downloaded!\n",
      "         Job 11: HR Business Partner, Director for Refrigeration and Air-Conditioning Division downloaded!\n",
      "         Job 12: Strategy Manager (Nordborg, DK) downloaded!\n",
      "         Job 13: Senior Strategy Consultant (Nordborg, DK) downloaded!\n",
      "         Job 14: HR Business Partner, Director for Refrigeration and Air-Conditioning Division downloaded!\n",
      "         Job 15: Strategy Manager (Nordborg, DK) downloaded!\n",
      "         Job 16: Business Controller (m/f/d) downloaded!\n",
      "         Job 17: Business Controller (m/f/d) downloaded!\n",
      "         Job 18: Strategy Manager (Nordborg, DK) downloaded!\n",
      "         Job 19: Senior Strategy Consultant (Nordborg, DK) downloaded!\n",
      "         Job 20: Embedded Software Developer downloaded!\n",
      "         Job 21: SAP Business Consultant - EWM downloaded!\n",
      "         Job 22: Process Owner PLM downloaded!\n",
      "         Job 23: Customer Service Director downloaded!\n",
      "         Job 24: Global Payroll Manager (m/f/d) downloaded!\n",
      "         Job 25: Lead Consultant, Performance Management downloaded!\n",
      "         Job 26: Category Manager, Facilities Management (m/f/d) downloaded!\n",
      "         Job 27: Product Portfolio Manager (m/f/d) downloaded!\n",
      "         Job 28: Senior Strategy Manager (Nordborg, DK) downloaded!\n",
      "         Job 29: Business Controller (m/f/d) downloaded!\n",
      "         Job 30: Supply Chain BU Lead (Easley, SC or Denmark) downloaded!\n",
      "         Job 31: Business Controller (m/f/d) downloaded!\n",
      "         Job 32: Senior Project Manager, Applications & Systems downloaded!\n",
      "         Job 33: Business Controller (m/f/d) downloaded!\n",
      "         Job 34: Finance Business Partner downloaded!\n",
      "         Job 35: Finance Business Partner downloaded!\n",
      "         Job 36: Sales Digital Business Director downloaded!\n",
      "         Job 37: HR Business Partner, Director for Refrigeration and Air-Conditioning Division downloaded!\n",
      "         Job 38: Senior Project Manager, Applications & Systems downloaded!\n",
      "         Job 39: Strategy Manager (Nordborg, DK) downloaded!\n",
      "Company 11: Nigel Frank International\n",
      "         No jobs found for Nigel Frank International\n",
      "Company 12: Tryg\n",
      "         No jobs found for Tryg\n",
      "Company 13: Too Good To Go\n",
      "         Job 1: Software Engineer - Java, Backend downloaded!\n",
      "         Job 2: Software Engineer - Java, Backend downloaded!\n",
      "         Job 3: Senior Software Engineer - Frontend, Web downloaded!\n",
      "         Job 4: Software Engineer - Java, Backend downloaded!\n",
      "         Job 5: Senior Software Engineer - Frontend, Web downloaded!\n",
      "         Job 6: Software Engineer - Java, Backend downloaded!\n",
      "         Job 7: Senior Software Engineer - Frontend, Web downloaded!\n",
      "         Job 8: Software Engineer - Java, Backend downloaded!\n",
      "         Job 9: Senior Software Engineer - Frontend, Web downloaded!\n",
      "         Job 10: Software Engineer - Java, Backend downloaded!\n",
      "         Job 11: Senior Software Engineer - Frontend, Web downloaded!\n",
      "Company 14: Mastercard\n",
      "         Job 1: Senior Java Developer downloaded!\n",
      "         Job 2: Senior Software Engineer downloaded!\n",
      "         Job 3: Senior BizOps Engineer downloaded!\n",
      "         Job 4: Senior BizOps Engineer downloaded!\n",
      "         Job 5: Senior BizOps Engineer downloaded!\n",
      "         Job 6: Senior BizOps Engineer downloaded!\n",
      "         Job 7: Senior BizOps Engineer downloaded!\n",
      "         Job 8: Product Manager downloaded!\n",
      "         Job 9: Senior Scheme Relationship Manager downloaded!\n",
      "         Job 10: Chief Software Architect downloaded!\n",
      "         Job 11: Senior BizOps Engineer downloaded!\n",
      "         Job 12: Senior BizOps Engineer downloaded!\n",
      "         Job 13: Product Manager downloaded!\n",
      "         Job 14: Senior Scheme Relationship Manager downloaded!\n",
      "         Job 15: Chief Software Architect downloaded!\n",
      "         Job 16: Product Manager downloaded!\n",
      "         Job 17: Senior BizOps Engineer downloaded!\n",
      "         Job 18: Chief Software Architect downloaded!\n",
      "         Job 19: Senior Scheme Relationship Manager downloaded!\n",
      "         Job 20: Software engineer downloaded!\n",
      "         Job 21: Senior Software Engineer downloaded!\n",
      "         Job 22: Software engineer downloaded!\n",
      "         Job 23: Senior Java Developer downloaded!\n",
      "         Job 24: Senior Software Engineer downloaded!\n",
      "         Job 25: Senior BizOps Engineer downloaded!\n",
      "         Job 26: Senior BizOps Engineer downloaded!\n",
      "         Job 27: Senior BizOps Engineer downloaded!\n",
      "         Job 28: Product Manager downloaded!\n",
      "         Job 29: Software engineer downloaded!\n",
      "         Job 30: Senior Java Developer downloaded!\n",
      "         Job 31: Senior Software Engineer downloaded!\n",
      "         Job 32: Senior BizOps Engineer downloaded!\n",
      "         Job 33: Senior BizOps Engineer downloaded!\n",
      "Company 15: Maersk\n",
      "         Job 1: Head of Standards Cold Chain downloaded!\n",
      "         Job 2: Subject Matter Expert, Methanol downloaded!\n",
      "         Job 3: Student Assistant for Container Research Team downloaded!\n",
      "         Job 4: Senior Research Scientist downloaded!\n",
      "         Job 5: Senior Software Engineer - API Gateway downloaded!\n",
      "         Job 6: Senior Software Engineer - API Gateway downloaded!\n",
      "Company 16: Danske Bank\n",
      "         Job 1: Senior/Chief Analyst, Compliance Risk Assessments downloaded!\n",
      "         Job 2: Model Validation Expert downloaded!\n",
      "Company 17: William Demant Holding\n",
      "         No jobs found for William Demant Holding\n",
      "Company 18: Nets\n",
      "         Job 1: Senior Cloud Engineer for Nets downloaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company 19: Ambu A/S\n",
      "         No jobs found for Ambu A/S\n",
      "Company 20: NNIT\n",
      "         Job 1: SDA/LAN/Wireless Network Service Architect downloaded!\n",
      "         Job 2: Technical Compliance Coordinator downloaded!\n",
      "         Job 3: SDA/LAN/Wireless Network Service Architect downloaded!\n",
      "         Job 4: Datacenter Networking Specialist downloaded!\n",
      "         Job 5: IT Infrastructure Program Manager downloaded!\n",
      "         Job 6: Cloud Architect downloaded!\n",
      "         Job 7: Advanced IT Infrastructure Project Manager downloaded!\n",
      "         Job 8: Technical Compliance Coordinator downloaded!\n",
      "         Job 9: Senior Business Intelligence Developer to join our exciting data journey downloaded!\n",
      "         Job 10: Datacenter Networking Specialist downloaded!\n",
      "         Job 11: Cloud Transformation Lead downloaded!\n",
      "Company 21: Bang & Olufsen\n",
      "         Job 1: Student Assistant, Producer downloaded!\n",
      "Company 22: DFDS\n",
      "         Job 1: Integration Architect downloaded!\n",
      "         Job 2: Business Integration Analyst downloaded!\n",
      "         Job 3: O365 Integration Engineer downloaded!\n",
      "         Job 4: Windows System Engineer Lead downloaded!\n",
      "Company 23: FLSmidth\n",
      "         Job 1: Customer Relations Manager, Denmark Cluster- Cement downloaded!\n",
      "         Job 2: Customer Relations Manager, Denmark Cluster- Cement downloaded!\n",
      "         Job 3: Group External Reporting Lead downloaded!\n",
      "         Job 4: Regional Inventory Manager - ECANA downloaded!\n",
      "         Job 5: Group External Reporting Lead downloaded!\n",
      "         Job 6: Student Assistant - Treasury downloaded!\n",
      "         Job 7: Payroll Specialist for Global Service downloaded!\n",
      "         Job 8: Senior Systems Engineer downloaded!\n",
      "         Job 9: Electrical Engineer downloaded!\n",
      "Company 24: Workday\n",
      "         No jobs found for Workday\n",
      "Company 25: Boston Consulting Group (BCG)\n",
      "         Job 1: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 2: Project Leader - Transform downloaded!\n",
      "         Job 3: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 4: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 5: IT Architect - Copenhagen downloaded!\n",
      "         Job 6: AI Security Engineer downloaded!\n",
      "         Job 7: Forward-deployed Data Engineer downloaded!\n",
      "         Job 8: Forward-deployed Data Engineer downloaded!\n",
      "         Job 9: Project Leader - Operations downloaded!\n",
      "         Job 10: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 11: Project Leader - Transform downloaded!\n",
      "         Job 12: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 13: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 14: IT Architect - Copenhagen downloaded!\n",
      "         Job 15: AI Security Engineer downloaded!\n",
      "         Job 16: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 17: AI Security Engineer downloaded!\n",
      "         Job 18: Project Leader - Transform downloaded!\n",
      "         Job 19: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 20: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 21: Project Leader - Operations downloaded!\n",
      "         Job 22: IT Architect - Copenhagen downloaded!\n",
      "         Job 23: Project Leader - Operations downloaded!\n",
      "         Job 24: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 25: IT Architect - Copenhagen downloaded!\n",
      "         Job 26: AI Security Engineer downloaded!\n",
      "         Job 27: Forward-deployed Data Engineer downloaded!\n",
      "         Job 28: Project Leader - Operations downloaded!\n",
      "         Job 29: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 30: Project Leader - Transform downloaded!\n",
      "         Job 31: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 32: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 33: Forward-deployed Data Engineer downloaded!\n",
      "         Job 34: Project Leader - Operations downloaded!\n",
      "         Job 35: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 36: Project Leader - Transform downloaded!\n",
      "         Job 37: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 38: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 39: IT Architect - Copenhagen downloaded!\n",
      "         Job 40: AI Security Engineer downloaded!\n",
      "         Job 41: Forward-deployed Data Engineer downloaded!\n",
      "         Job 42: Project Leader - Transform downloaded!\n",
      "         Job 43: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 44: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 45: IT Architect - Copenhagen downloaded!\n",
      "         Job 46: AI Security Engineer downloaded!\n",
      "         Job 47: Forward-deployed Data Engineer downloaded!\n",
      "         Job 48: Project Leader - Operations downloaded!\n",
      "         Job 49: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 50: Project Leader - Transform downloaded!\n",
      "         Job 51: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 52: Forward-deployed Data Engineer downloaded!\n",
      "         Job 53: Project Leader - Operations downloaded!\n",
      "         Job 54: Project Leader, Principal, Partner at DigitalBCG downloaded!\n",
      "         Job 55: Project Leader - Transform downloaded!\n",
      "         Job 56: Senior IT Consultant - Copenhagen downloaded!\n",
      "         Job 57: Senior IT Architect - Copenhagen downloaded!\n",
      "         Job 58: IT Architect - Copenhagen downloaded!\n",
      "         Job 59: AI Security Engineer downloaded!\n",
      "Company 26: Antler\n",
      "         Job 1: Program Intern | Antler Denmark downloaded!\n",
      "         Job 2: Product Manager & Startup Founder downloaded!\n",
      "         Job 3: Program Intern | Antler Denmark downloaded!\n",
      "         Job 4: Product Manager & Startup Founder downloaded!\n",
      "Company 27: DTU - Technical University of Denmark\n",
      "         No jobs found for DTU - Technical University of Denmark\n",
      "Company 28: ATLANT 3D\n",
      "         No jobs found for ATLANT 3D\n",
      "Company 29: Silo AI\n",
      "         Job 1: AI Engineer - MLOps - Denmark downloaded!\n",
      "Company 30: ROCKWOOL Group\n",
      "         No jobs found for ROCKWOOL Group\n",
      "Company 31: Corti\n",
      "         No jobs found for Corti\n",
      "Company 32: Accenture Nordics\n",
      "         Job 1: Contracting Counsel downloaded!\n",
      "         Job 2: Digital Tech Developer - Accenture Song - Copenhagen downloaded!\n",
      "         Job 3: MES Engineer / MES Technical Consultant downloaded!\n",
      "Company 33: TELUS International AI Data Solutions\n",
      "         No jobs found for TELUS International AI Data Solutions\n",
      "Company 34: Appen\n",
      "         Job 1: Mobile developer ios downloaded!\n",
      "         Job 2: Webanalytiker downloaded!\n",
      "Company 35: IT-Universitetet i København\n",
      "         Job 1: Integrations og applikationsspecialist til IT-afdelingen  på IT-Universitetet i København (Genopslag) downloaded!\n",
      "Company 36: Capgemini\n",
      "         Job 1: IT System Administrator downloaded!\n",
      "         Job 2: Data Engineer Consultant downloaded!\n",
      "         Job 3: Financial Controller downloaded!\n",
      "         Job 4: Software Engineer downloaded!\n",
      "         Job 5: Network Architect downloaded!\n",
      "         Job 6: Data Engineer Consultant downloaded!\n",
      "         Job 7: Financial Controller downloaded!\n",
      "         Job 8: Software Engineer downloaded!\n",
      "         Job 9: Oracle Database Administrator downloaded!\n",
      "Company 37: TELUS International\n",
      "         No jobs found for TELUS International\n",
      "Company 38: Mindway AI\n",
      "         Job 1: Software Engineer downloaded!\n",
      "\n",
      "Total 230 jobs downloaded!\n"
     ]
    }
   ],
   "source": [
    "country_name= \"Denmark\"\n",
    "geoId=\"104514075\"\n",
    "companies = ['Trustpilot', 'BESTSELLER', 'Canonical', 'HCLTech', 'Randstad Danmark', 'the LEGO Group', 'Mover Systems', 'Netcompany', 'Schibsted', 'Danfoss', 'Nigel Frank International', 'Tryg', 'Too Good To Go', 'Mastercard', 'Maersk', 'Danske Bank', 'William Demant Holding', 'Nets', 'Ambu A/S', 'NNIT', 'Bang & Olufsen', 'DFDS', 'FLSmidth', 'Workday', 'Boston Consulting Group (BCG)', 'Antler', 'DTU - Technical University of Denmark', 'ATLANT 3D', 'Silo AI', 'ROCKWOOL Group', 'Corti', 'Accenture Nordics', 'TELUS International AI Data Solutions', 'Appen', 'IT-Universitetet i København', 'Capgemini', 'TELUS International', 'Mindway AI']\n",
    "\n",
    "\n",
    "print(\"Country: \", country_name)\n",
    "print()\n",
    "\n",
    "scraper = LinkedinScraper(country_name, geoId, companies )\n",
    "scraper.scrape_jobs(\"FS_jobs_denmark.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277aafd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
